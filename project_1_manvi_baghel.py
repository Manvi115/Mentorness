# -*- coding: utf-8 -*-
"""Project_1_Manvi_Baghel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zbpmwp2pNmToHpUMcsCyK4x1WtFAV_VD

#Importing Necessary Libraries
"""

import pandas as pd

from sklearn.impute import SimpleImputer
# Impute missing values with the mean

from imblearn.over_sampling import SMOTE
#SMOTE:Synthetic Minority Over-sampling Technique is used to deal with class imbalance by creating synthetic samples of the minority class.

from sklearn.linear_model import LogisticRegression
#classification algorithm used to model the probability of a certain class or event

from sklearn.metrics import classification_report, confusion_matrix
#to evaluate the performance of the classification model.

import seaborn as sns # for data visualization
import matplotlib.pyplot as plt # for data visualization

"""# Loading Dataset"""

# Load the training dataset
train_data = pd.read_csv('/content/train_data.csv')

# Load the testing dataset
test_data = pd.read_csv('/content/test_data.csv')

"""# Data Visualization

"""

#Dataset Size

# for training data
print("For training data: ")
print("Number of rows:", train_data.shape[0])
print("Number of columns:", train_data.shape[1])
print("No. of elements: ", train_data.size)
print("\n")

# for testing data
print("/n For testing data: ")
print("Number of rows:", test_data.shape[0])
print("Number of columns:", test_data.shape[1])
print("No. of elements: ", test_data.size)

# column headings

print(train_data.columns)

# Summary statistics
print(train_data.describe())

print(train_data.head())

"""# Exploratory Data Analysis"""

print(train_data.columns)

# Histogram for a numerical variable
plt.figure(figsize=(8, 6))
sns.histplot(data=train_data, x='Income', bins=30, kde=True)
plt.title('Distribution of Income')
plt.show()

# Count plot for a categorical variable
plt.figure(figsize=(8, 6))
sns.countplot(data=train_data, x='Education level')
plt.title('Count of Education Levels')
plt.xticks(rotation=45)
plt.show()

# Plotting the distribution of the target variable 'Is high risk'
plt.figure(figsize=(8, 6))
sns.countplot(x='Is high risk', data=train_data)
plt.title('Distribution of Is high risk')
plt.show()

# Create a figure and axis
fig, axs = plt.subplots(2, 2, figsize=(12, 10))

# Plot histograms for 'Children count', 'Income', 'Age', and 'Employment length'
sns.histplot(train_data['Children count'], ax=axs[0, 0])
sns.histplot(train_data['Income'], ax=axs[0, 1])
sns.histplot(train_data['Age'], ax=axs[1, 0])
sns.histplot(train_data['Employment length'], ax=axs[1, 1])

# Set titles for each subplot
axs[0, 0].set_title('Distribution of Children count')
axs[0, 1].set_title('Distribution of Income')
axs[1, 0].set_title('Distribution of Age')
axs[1, 1].set_title('Distribution of Employment length')

# Adjust layout
plt.tight_layout()

# Show the plot
plt.show()

# Plotting the distribution of 'Gender' with respect to 'Is high risk'
plt.figure(figsize=(8, 6))
sns.countplot(x='Gender', hue='Is high risk', data=train_data)
plt.title('Distribution of Gender with respect to Is high risk')
plt.show()

"""# Data Preprocessing for Logistic Regression"""

# Dropping ID column as it's not needed for prediction
train_data.drop('ID', axis=1, inplace=True)
test_data.drop('ID', axis=1, inplace=True)

# Encoding categorical variables, i.e. giving binary values to categorical values like Male/Female
train_data = pd.get_dummies(train_data)
test_data = pd.get_dummies(test_data)

# Separating features and target variable for training and testing data
X_train = train_data.drop('Is high risk', axis=1)
y_train = train_data['Is high risk']
X_test = test_data.drop('Is high risk', axis=1)
y_test = test_data['Is high risk']

# Imputing missing values with the mean
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

# Performing SMOTE on training data
#Creating an instance of the SMOTE class with a specified random state (42 in this case) for reproducibility
smote = SMOTE(random_state=42)
#Resampling the dataset, increasing the number of samples in the minority class (Is high risk) to balance the class distribution.
X_resampled, y_resampled = smote.fit_resample(X_train_imputed, y_train)

"""# Training the Logistic Regression Model:

"""

# Train the logistic regression model with adjusted class weights
model = LogisticRegression(max_iter=1000, class_weight='balanced')
model.fit(X_resampled, y_resampled)

"""# Making Predictions from Logistic Regression :"""

# Make predictions on testing data
y_pred = model.predict(X_test_imputed)

# Display predictions
print("Predicted Approval Status:")
print(y_pred)

import numpy as np

# Choose the index of the row you want to inspect
row_index = 2  # Change this to the index of the row you want to inspect

# Get the features of the selected row
selected_row_features = X_test_imputed[row_index]

# Reshape the features for prediction
selected_row_features = selected_row_features.reshape(1, -1)

# Predict the approval status for the selected row
predicted_status = model.predict(selected_row_features)[0]

# Display the selected row features, actual approval status, and predicted approval status
print("Selected Row Features:")
print(selected_row_features)
print("Predicted Approval Status:", predicted_status)

"""# Evaluating the Logistic Regression Model:

"""

# Evaluate the model
print('Classification Report:')
print(classification_report(y_test, y_pred))

print('Confusion Matrix:')
print(confusion_matrix(y_test, y_pred))

"""# Graphical Analysis of Logistic Regression Model"""

# Plotting the distribution of 'males' with respect to 'Predicted Approval Status'
plt.figure(figsize=(8, 6))
sns.countplot(x='Gender_M', hue=y_pred, data=test_data)
plt.title('Distribution of males with respect to Predicted Approval Status')
plt.show()

# Plotting the distribution of 'females' with respect to 'Predicted Approval Status'
plt.figure(figsize=(8, 6))
sns.countplot(x='Gender_F', hue=y_pred, data=test_data)
plt.title('Distribution of females with respect to Predicted Approval Status')
plt.show()

# Plotting the distribution of 'Income' with respect to 'Predicted Approval Status'
plt.figure(figsize=(8, 6))
sns.histplot(x='Income', hue=y_pred, data=test_data, bins=30, kde=True)
plt.title('Distribution of Income with respect to Predicted Approval Status')
plt.show()

# Plotting the distribution of 'Age' with respect to 'Predicted Approval Status'
plt.figure(figsize=(8, 6))
sns.histplot(x='Age', hue=y_pred, data=test_data, bins=30, kde=True)
plt.title('Distribution of Age with respect to Predicted Approval Status')
plt.show()

# Plotting the distribution of 'Children count' with respect to 'Predicted Approval Status'
plt.figure(figsize=(8, 6))
sns.countplot(x='Children count', hue=y_pred, data=test_data)
plt.title('Distribution of Children count with respect to Predicted Approval Status')
plt.show()

"""#**Decision Trees**

# Importing Necessary Libraries
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.impute import SimpleImputer

"""# Loading Dataset"""

# Loading the training and test data again
df_train = pd.read_csv('/content/train_data.csv')
df_test = pd.read_csv('/content/test_data.csv')

"""# Data Preprocessing for Decision Trees"""

# Separating features (X) and target variable (y) for training data
X_train = df_train.drop('Is high risk', axis=1)
y_train = df_train['Is high risk']

# Separating features (X) and target variable (y) for test data
X_test = df_test.drop('Is high risk', axis=1)
y_test = df_test['Is high risk']

# Encoding categorical variables, i.e. giving binary values to categorical values like Male/Female
X_train = pd.get_dummies(X_train)
X_test = pd.get_dummies(X_test)

# Initializing the imputer
# to replace the missing values with the mean of the non-missing values in the same column
imputer = SimpleImputer(strategy='mean')

# Fitting and transforming the imputer on the training data
# i.e. calculating the mean for each column, storing it in the variable and replaces missing values with those means
X_train_imputed = imputer.fit_transform(X_train)

# Converting the imputed data back to a DataFrame with the original column names
X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train.columns)

# Combining the features and target variable into a single DataFrame
train_data = X_train_imputed.copy()
train_data['Is high risk'] = y_train

# Dropping rows with missing target values
train_data.dropna(subset=['Is high risk'], inplace=True)

# Separating the target variable from the features
y_train_cleaned = train_data['Is high risk']
X_train_cleaned = train_data.drop(columns=['Is high risk'])

"""# Initialisation of Decision Tree Classifier"""

# Initialize the decision tree classifier
clf = DecisionTreeClassifier(random_state=42)

# Fit the model on the cleaned training data
clf.fit(X_train_cleaned, y_train_cleaned)

# Align the feature names in the test data with those in the training data
X_test_aligned = X_test.reindex(columns=X_train_cleaned.columns, fill_value=0)

"""# Making Predictions from Decision Trees"""

# Predict the target variable for the test set
y_pred = clf.predict(X_test_aligned)

"""# Evaluating the Decision Tree Classifier"""

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Display classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Display confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

"""# Graphical Analysis of the Decision Tree"""

# Plotting the distribution of 'males' with respect to 'Predicted Approval Status'
plt.figure(figsize=(8, 6))
sns.countplot(x='Gender_M', hue=y_pred, data=test_data)
plt.title('Distribution of males with respect to Predicted Approval Status')
plt.show()

# Plotting the distribution of 'females' with respect to 'Predicted Approval Status'
plt.figure(figsize=(8, 6))
sns.countplot(x='Gender_F', hue=y_pred, data=test_data)
plt.title('Distribution of females with respect to Predicted Approval Status')
plt.show()

# Plotting the distribution of 'Income' with respect to 'Predicted Approval Status'
plt.figure(figsize=(8, 6))
sns.histplot(x='Income', hue=y_pred, data=test_data, bins=30, kde=True)
plt.title('Distribution of Income with respect to Predicted Approval Status')
plt.show()

# Plotting the distribution of 'Age' with respect to 'Predicted Approval Status'
plt.figure(figsize=(8, 6))
sns.histplot(x='Age', hue=y_pred, data=test_data, bins=30, kde=True)
plt.title('Distribution of Age with respect to Predicted Approval Status')
plt.show()

# Plotting the distribution of 'Children count' with respect to 'Predicted Approval Status'
plt.figure(figsize=(8, 6))
sns.countplot(x='Children count', hue=y_pred, data=test_data)
plt.title('Distribution of Children count with respect to Predicted Approval Status')
plt.show()