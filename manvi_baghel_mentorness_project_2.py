# -*- coding: utf-8 -*-
"""Manvi_Baghel_Mentorness_Project_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wInB6EjS3QEuGDpmt3kYyItGVB0XBYWQ

# Importing important libraries
"""

import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.metrics import mean_squared_error
import numpy as np
import seaborn as snstantm

# Loading the dataset
df = pd.read_csv('/content/Super_Store_data.csv', encoding='latin1')

"""# EDA"""

num_rows, num_columns = df.shape
print(f"Number of rows: {num_rows}, Number of columns: {num_columns}")

# Displaying the first few rows of the dataset
print(df.head())

furniture = df.loc[df['Category'] == 'Furniture']
furniture['Order Date'].min(), furniture['Order Date'].max()

"""# Data Preprocessing"""

cols = ['Row ID', 'Order ID', 'Ship Date', 'Ship Mode', 'Customer ID', 'Customer Name', 'Segment', 'Country', 'City', 'State', 'Postal Code', 'Region', 'Product ID', 'Category', 'Sub-Category', 'Product Name', 'Quantity', 'Discount', 'Profit']
df.drop(cols, axis=1, inplace=True)
df = df.sort_values('Order Date')
df.isnull().sum()

num_rows, num_columns = df.shape
print(f"Number of rows: {num_rows}, Number of columns: {num_columns}")

# Displaying the first few rows of the dataset after data preprocessing
print(df.head())

"""# Seasonal Decomposition"""

print(df.columns)

# Assuming 'df' is your DataFrame
y = df['Sales']

# Converting 'Order Date' to datetime format
df['Order Date'] = pd.to_datetime(df['Order Date'])

# Setting 'Order Date' as the index
df.set_index('Order Date', inplace=True)

# Resampling the data to ensure a consistent daily frequency
y = df['Sales'].resample('D').sum()

# Setting the figure size
plt.rcParams['figure.figsize'] = 18, 8

# Performing seasonal decomposition
decomposition = sm.tsa.seasonal_decompose(y, model='additive')

# Ploting the decomposition components
fig = decomposition.plot()
plt.show()

# Seasonal plot
plt.figure(figsize=(12, 6))
sns.lineplot(x=df.index.month, y=df['Sales'], hue=df.index.year, palette='viridis')
plt.title('Seasonal Plot of Furniture Sales')
plt.xlabel('Month')
plt.ylabel('Sales')
plt.legend(title='Year', loc='upper right')
plt.grid(True)
plt.show()

"""# Model Selection and Training"""

# Aggregating sales data by month
monthly_sales = df['Sales'].resample('M').sum()

# Splitting the data into training and testing sets
train_size = int(len(monthly_sales) * 0.8)
train, test = monthly_sales[:train_size], monthly_sales[train_size:]

# Fitting an Exponential Smoothing model
model = ExponentialSmoothing(train, seasonal='add', seasonal_periods=12)
model_fit = model.fit()

"""# Forecasting Results"""

# Making predictions for the test set
predictions = model_fit.forecast(len(test))

# Visualizing the actual vs. predicted values
plt.figure(figsize=(15, 6))
plt.plot(train.index, train, label='Training')
plt.plot(test.index, test, label='Testing')
plt.plot(test.index, predictions, label='Predictions')
plt.title('Actual vs. Predicted Sales')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.legend()
plt.show()

"""# Evaluation"""

# Calculating RMSE (Root Mean Squared Error) to evaluate the model
rmse = np.sqrt(mean_squared_error(test, predictions))
print(f'RMSE: {rmse}')
